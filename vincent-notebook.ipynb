{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28323d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: preprocessor in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (1.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: vaderSentiment in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from vaderSentiment) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torchmetrics in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: packaging in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from packaging->torchmetrics) (3.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentence-transformers in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.10.0)\n",
      "Requirement already satisfied: tqdm in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.1.2)\n",
      "Requirement already satisfied: nltk in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: torchvision in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.13.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.1.97)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.21.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: numpy in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scipy in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: filelock in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: requests in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: click in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install preprocessor\n",
    "!pip install vaderSentiment\n",
    "!pip install torchmetrics\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc09174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import preprocessor as p\n",
    "import re\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4764fd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vincentdandenault/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vincentdandenault/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3bfdddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'Data'\n",
    "censored_path = 'censored_tweets'\n",
    "control_path = 'plusone_control_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ede9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for r, d, f in os.walk('Data'):\n",
    "    for file in f:\n",
    "        if 'withheldtweets.json' in file or 'plus_one_control.json' in file:  # alt: if â€˜control' in file:\n",
    "            dfs.append(pd.read_json('%s/%s' % (r, file), lines=True))\n",
    "\n",
    "df_cen = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12371fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>linked</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>withheld_copyright</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-26 10:54:27+00:00</td>\n",
       "      <td>1365253891839971330</td>\n",
       "      <td>1365253891839971328</td>\n",
       "      <td>CHINE - Depuis le 1er janvier 2021, une loi pe...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>fr</td>\n",
       "      <td>2021-02-26 10:54:27.662</td>\n",
       "      <td>quoted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-26 10:48:35+00:00</td>\n",
       "      <td>1365252415444946945</td>\n",
       "      <td>1365252415444946944</td>\n",
       "      <td>#Balakot \\nPak Army is our pride â¤ï¸ğŸ‘ https://t...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-02-26 10:48:35.662</td>\n",
       "      <td>no</td>\n",
       "      <td>[0, 35]</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>{'media': [{'id': 1365252409015033857, 'id_str...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-26 10:45:51+00:00</td>\n",
       "      <td>1365251727574900738</td>\n",
       "      <td>1365251727574900736</td>\n",
       "      <td>RT @ZaidZamanHamid: Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>ur</td>\n",
       "      <td>2021-02-26 10:45:51.661</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'created_at': 'Thu Feb 25 18:59:12 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-26 10:45:51+00:00</td>\n",
       "      <td>1365251727574900738</td>\n",
       "      <td>1365251727574900736</td>\n",
       "      <td>RT @ZaidZamanHamid: Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>ur</td>\n",
       "      <td>2021-02-26 10:45:51.661</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'created_at': 'Thu Feb 25 18:59:12 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-26 10:38:57+00:00</td>\n",
       "      <td>1365249991137251328</td>\n",
       "      <td>1365249991137251328</td>\n",
       "      <td>RT @SaniaNishtar: Ø³ÛŒØ¯ Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ú©Ø§ ØªØ¹Ù„Ù‚ Ù‚Ø¨Ø§Ø¦Ù„ÛŒ Ø¶...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>ur</td>\n",
       "      <td>2021-02-26 10:38:57.662</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'created_at': 'Fri Feb 26 05:23:00 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-26 10:10:45+00:00</td>\n",
       "      <td>1365242894362279938</td>\n",
       "      <td>1365242894362279936</td>\n",
       "      <td>RT @mosa_abumarzook: ÙÙŠ Ù…Ø«Ù„ ÙØ¬Ø± Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ… Ù‚Ø¨Ù„ ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>ar</td>\n",
       "      <td>2021-02-26 10:10:45.659</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IL]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'created_at': 'Thu Feb 25 19:04:40 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-26 10:10:45+00:00</td>\n",
       "      <td>1365242894362279938</td>\n",
       "      <td>1365242894362279936</td>\n",
       "      <td>RT @mosa_abumarzook: ÙÙŠ Ù…Ø«Ù„ ÙØ¬Ø± Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ… Ù‚Ø¨Ù„ ...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>ar</td>\n",
       "      <td>2021-02-26 10:10:45.659</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IL]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'created_at': 'Thu Feb 25 19:04:40 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-26 10:10:46+00:00</td>\n",
       "      <td>1365242898569134080</td>\n",
       "      <td>1365242898569134080</td>\n",
       "      <td>RT @Saimhun: Mujhe aj bhi batting ki bari ni d...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>hi</td>\n",
       "      <td>2021-02-26 10:10:46.662</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>{'media': [{'id': 1365238103892516864, 'id_str...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'created_at': 'Fri Feb 26 09:51:44 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-26 10:10:46+00:00</td>\n",
       "      <td>1365242898569134080</td>\n",
       "      <td>1365242898569134080</td>\n",
       "      <td>RT @Saimhun: Mujhe aj bhi batting ki bari ni d...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>hi</td>\n",
       "      <td>2021-02-26 10:10:46.662</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>{'media': [{'id': 1365238103892516864, 'id_str...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'created_at': 'Fri Feb 26 09:51:44 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-02-26 10:59:24+00:00</td>\n",
       "      <td>1365255137552457730</td>\n",
       "      <td>1365255137552457728</td>\n",
       "      <td>RT @iVeenaKhan: (Ø§Û’ Ù¾ÛŒØºÙ…Ø¨Ø±ï·º! Ù„ÙˆÚ¯ÙˆÚº Ø³Û’) Ú©ÛÛ Ø¯Ùˆ ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>low</td>\n",
       "      <td>ur</td>\n",
       "      <td>2021-02-26 10:59:24.663</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'created_at': 'Fri Feb 26 05:42:25 +0000 2021...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id               id_str  \\\n",
       "0 2021-02-26 10:54:27+00:00  1365253891839971330  1365253891839971328   \n",
       "1 2021-02-26 10:48:35+00:00  1365252415444946945  1365252415444946944   \n",
       "2 2021-02-26 10:45:51+00:00  1365251727574900738  1365251727574900736   \n",
       "3 2021-02-26 10:45:51+00:00  1365251727574900738  1365251727574900736   \n",
       "4 2021-02-26 10:38:57+00:00  1365249991137251328  1365249991137251328   \n",
       "5 2021-02-26 10:10:45+00:00  1365242894362279938  1365242894362279936   \n",
       "6 2021-02-26 10:10:45+00:00  1365242894362279938  1365242894362279936   \n",
       "7 2021-02-26 10:10:46+00:00  1365242898569134080  1365242898569134080   \n",
       "8 2021-02-26 10:10:46+00:00  1365242898569134080  1365242898569134080   \n",
       "9 2021-02-26 10:59:24+00:00  1365255137552457730  1365255137552457728   \n",
       "\n",
       "                                                text  \\\n",
       "0  CHINE - Depuis le 1er janvier 2021, une loi pe...   \n",
       "1  #Balakot \\nPak Army is our pride â¤ï¸ğŸ‘ https://t...   \n",
       "2  RT @ZaidZamanHamid: Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº...   \n",
       "3  RT @ZaidZamanHamid: Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº...   \n",
       "4  RT @SaniaNishtar: Ø³ÛŒØ¯ Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ú©Ø§ ØªØ¹Ù„Ù‚ Ù‚Ø¨Ø§Ø¦Ù„ÛŒ Ø¶...   \n",
       "5  RT @mosa_abumarzook: ÙÙŠ Ù…Ø«Ù„ ÙØ¬Ø± Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ… Ù‚Ø¨Ù„ ...   \n",
       "6  RT @mosa_abumarzook: ÙÙŠ Ù…Ø«Ù„ ÙØ¬Ø± Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ… Ù‚Ø¨Ù„ ...   \n",
       "7  RT @Saimhun: Mujhe aj bhi batting ki bari ni d...   \n",
       "8  RT @Saimhun: Mujhe aj bhi batting ki bari ni d...   \n",
       "9  RT @iVeenaKhan: (Ø§Û’ Ù¾ÛŒØºÙ…Ø¨Ø±ï·º! Ù„ÙˆÚ¯ÙˆÚº Ø³Û’) Ú©ÛÛ Ø¯Ùˆ ...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...       True   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "5  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "6  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "7  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "8  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "9  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0                    NaN                        NaN                  NaN   \n",
       "1                    NaN                        NaN                  NaN   \n",
       "2                    NaN                        NaN                  NaN   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4                    NaN                        NaN                  NaN   \n",
       "5                    NaN                        NaN                  NaN   \n",
       "6                    NaN                        NaN                  NaN   \n",
       "7                    NaN                        NaN                  NaN   \n",
       "8                    NaN                        NaN                  NaN   \n",
       "9                    NaN                        NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  ... filter_level lang            timestamp_ms  \\\n",
       "0                      NaN  ...          low   fr 2021-02-26 10:54:27.662   \n",
       "1                      NaN  ...          low   en 2021-02-26 10:48:35.662   \n",
       "2                      NaN  ...          low   ur 2021-02-26 10:45:51.661   \n",
       "3                      NaN  ...          low   ur 2021-02-26 10:45:51.661   \n",
       "4                      NaN  ...          low   ur 2021-02-26 10:38:57.662   \n",
       "5                      NaN  ...          low   ar 2021-02-26 10:10:45.659   \n",
       "6                      NaN  ...          low   ar 2021-02-26 10:10:45.659   \n",
       "7                      NaN  ...          low   hi 2021-02-26 10:10:46.662   \n",
       "8                      NaN  ...          low   hi 2021-02-26 10:10:46.662   \n",
       "9                      NaN  ...          low   ur 2021-02-26 10:59:24.663   \n",
       "\n",
       "      linked display_text_range  withheld_in_countries  \\\n",
       "0     quoted                NaN                    NaN   \n",
       "1         no            [0, 35]                   [IN]   \n",
       "2         no                NaN                   [IN]   \n",
       "3  retweeted                NaN                   [IN]   \n",
       "4         no                NaN                   [IN]   \n",
       "5         no                NaN                   [IL]   \n",
       "6  retweeted                NaN                   [IL]   \n",
       "7         no                NaN                   [IN]   \n",
       "8  retweeted                NaN                   [IN]   \n",
       "9         no                NaN                   [IN]   \n",
       "\n",
       "                                   extended_entities  possibly_sensitive  \\\n",
       "0                                                NaN                 NaN   \n",
       "1  {'media': [{'id': 1365252409015033857, 'id_str...                 0.0   \n",
       "2                                                NaN                 NaN   \n",
       "3                                                NaN                 NaN   \n",
       "4                                                NaN                 NaN   \n",
       "5                                                NaN                 NaN   \n",
       "6                                                NaN                 NaN   \n",
       "7  {'media': [{'id': 1365238103892516864, 'id_str...                 0.0   \n",
       "8  {'media': [{'id': 1365238103892516864, 'id_str...                 0.0   \n",
       "9                                                NaN                 NaN   \n",
       "\n",
       "                                    retweeted_status withheld_copyright  \n",
       "0                                                NaN                NaN  \n",
       "1                                                NaN                NaN  \n",
       "2  {'created_at': 'Thu Feb 25 18:59:12 +0000 2021...                NaN  \n",
       "3  {'created_at': 'Thu Feb 25 18:59:12 +0000 2021...                NaN  \n",
       "4  {'created_at': 'Fri Feb 26 05:23:00 +0000 2021...                NaN  \n",
       "5  {'created_at': 'Thu Feb 25 19:04:40 +0000 2021...                NaN  \n",
       "6  {'created_at': 'Thu Feb 25 19:04:40 +0000 2021...                NaN  \n",
       "7  {'created_at': 'Fri Feb 26 09:51:44 +0000 2021...                NaN  \n",
       "8  {'created_at': 'Fri Feb 26 09:51:44 +0000 2021...                NaN  \n",
       "9  {'created_at': 'Fri Feb 26 05:42:25 +0000 2021...                NaN  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cen.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a9fad",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6939f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['id','text', 'truncated', 'user', 'user-location', 'user-verified', 'user-followers_count', \\\n",
    "                    'withheld_in_countries', 'entities', 'lang', 'extended_entities', \\\n",
    "                   'possibly_sensitive', 'extended_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8b21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "worthKeeping = [\"text\", \"truncated\", \"user\",\n",
    "                \"withheld_in_countries\", \"entities\", \"lang\",\n",
    "                \"possibly_sensitive\", \"extended_tweet\"]\n",
    "df_cen = df_cen[worthKeeping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a9ed824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cen['possibly_sensitive'] = df_cen['possibly_sensitive'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714e4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw = df_cen.values\n",
    "for line in dfRaw:\n",
    "    #if not pd.isna(line[-1]):\n",
    "        #line[0] = line[-1][\"full_text\"]\n",
    "        \n",
    "    #remove urls from tweets\n",
    "    #they are shortened anyway so we can't make use of them\n",
    "    line[0] = re.sub(r'http\\S+', '', str(line[0]))\n",
    "    \n",
    "    #flatten retweets\n",
    "    line[0] = re.sub(r'RT @\\S+:', '', str(line[0]))\n",
    "\n",
    "dfRaw = np.delete(dfRaw, len(worthKeeping)-1, axis=1) #remove \"extended_tweet\"\n",
    "worthKeeping.remove(\"extended_tweet\")\n",
    "\n",
    "dfRaw = np.delete(dfRaw, 1, axis=1) #remove \"truncated\"\n",
    "worthKeeping.remove(\"truncated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1a586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in dfRaw:\n",
    "    line[3] = [x[\"text\"] for x in line[3][\"hashtags\"]]\n",
    "worthKeeping[3] = \"hashtags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f526a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a feature for user-verified and user-followers_count\n",
    "verified = [line[1][\"verified\"] for line in dfRaw]\n",
    "followers = [line[1][\"followers_count\"] for line in dfRaw]\n",
    "user_id = [line[1][\"id\"] for line in dfRaw]\n",
    "\n",
    "#for the location, Rebekah suggested to only spot the country name and discard the rest\n",
    "listOfCountries = ['Afghanistan', 'Aland Islands', 'Albania', 'Algeria', 'American Samoa', 'Andorra', 'Angola', 'Anguilla', 'Antarctica', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia, Plurinational State of', 'Bonaire, Sint Eustatius and Saba', 'Bosnia and Herzegovina', 'Botswana', 'Bouvet Island', 'Brazil', 'British Indian Ocean Territory', 'Brunei Darussalam', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde', 'Cayman Islands', 'Central African Republic', 'Chad', 'Chile', 'China', 'Christmas Island', 'Cocos (Keeling) Islands', 'Colombia', 'Comoros', 'Congo', 'Congo, The Democratic Republic of the', 'Cook Islands', 'Costa Rica', \"CÃ´te d'Ivoire\", 'Croatia', 'Cuba', 'CuraÃ§ao', 'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia', 'Falkland Islands (Malvinas)', 'Faroe Islands', 'Fiji', 'Finland', 'France', 'French Guiana', 'French Polynesia', 'French Southern Territories', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'Grenada', 'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Heard Island and McDonald Islands', 'Holy See (Vatican City State)', 'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran, Islamic Republic of', 'Iraq', 'Ireland', 'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kazakhstan', 'Kenya', 'Kiribati', \"Korea, Democratic People's Republic of\", 'Korea, Republic of', 'Kuwait', 'Kyrgyzstan', \"Lao People's Democratic Republic\", 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macao', 'Macedonia, Republic of', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Martinique', 'Mauritania', 'Mauritius', 'Mayotte', 'Mexico', 'Micronesia, Federated States of', 'Moldova, Republic of', 'Monaco', 'Mongolia', 'Montenegro', 'Montserrat', 'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Niue', 'Norfolk Island', 'Northern Mariana Islands', 'Norway', 'Oman', 'Pakistan', 'Palau', 'Palestinian Territory, Occupied', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Pitcairn', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'RÃ©union', 'Romania', 'Russian Federation', 'Rwanda', 'Saint BarthÃ©lemy', 'Saint Helena, Ascension and Tristan da Cunha', 'Saint Kitts and Nevis', 'Saint Lucia', 'Saint Martin (French part)', 'Saint Pierre and Miquelon', 'Saint Vincent and the Grenadines', 'Samoa', 'San Marino', 'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia', 'Seychelles', 'Sierra Leone', 'Singapore', 'Sint Maarten (Dutch part)', 'Slovakia', 'Slovenia', 'Solomon Islands', 'Somalia', 'South Africa', 'South Georgia and the South Sandwich Islands', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'South Sudan', 'Svalbard and Jan Mayen', 'Swaziland', 'Sweden', 'Switzerland', 'Syrian Arab Republic', 'Taiwan, Province of China', 'Tajikistan', 'Tanzania, United Republic of', 'Thailand', 'Timor-Leste', 'Togo', 'Tokelau', 'Tonga', 'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Turkmenistan', 'Turks and Caicos Islands', 'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States', 'United States Minor Outlying Islands', 'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela, Bolivarian Republic of', 'Viet Nam', 'Virgin Islands, British', 'Virgin Islands, U.S.', 'Wallis and Futuna', 'Yemen', 'Zambia', 'Zimbabwe']\n",
    "def findCountry(x):\n",
    "    for country in listOfCountries:\n",
    "        if x and country in x:\n",
    "            return country\n",
    "    return None\n",
    "\n",
    "location = [findCountry(line[1][\"location\"]) for line in dfRaw]\n",
    "\n",
    "dfRaw = np.c_[dfRaw, verified, followers, location, user_id]\n",
    "worthKeeping += [\"verified_account\", \"followers_count\", \"location\", \"user_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "163abaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "withheld = []\n",
    "for line in dfRaw:\n",
    "    if not isinstance(line[2], list):\n",
    "        line[2] = []\n",
    "    withheld.append(len(line[2]) != 0)\n",
    "        \n",
    "dfRaw = np.c_[dfRaw, withheld]\n",
    "worthKeeping += [\"withheld_anywhere\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c77b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = SentimentIntensityAnalyzer()\n",
    "#we made the assumption that sentiment analysis for this analyzer only works for english\n",
    "res = np.array([[x for x in sentiment.polarity_scores(line[0]).values()] if line[4] == \"en\" else [0.0, 0.0, 0.0, 0.0] for line in dfRaw])\n",
    "\n",
    "dfRaw = np.c_[dfRaw, res]\n",
    "worthKeeping += [\"neg\", \"neu\", \"pos\", \"compound\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805e2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#popularity feature:\n",
    "#build a score based on the values of followers_count, favourites_count, statuses_count\n",
    "#compute a score from 0 to 1 for each, with (x - min)/(max - min), then comptute the average of these scores \n",
    "\n",
    "followers_count = np.array([line[1][\"followers_count\"] for line in dfRaw])\n",
    "favourites_count = np.array([line[1][\"favourites_count\"] for line in dfRaw])\n",
    "statuses_count = np.array([line[1][\"statuses_count\"] for line in dfRaw])\n",
    "\n",
    "def normalize(array):\n",
    "    return (array - np.min(array)) / (np.max(array) - np.min(array))\n",
    "\n",
    "score = (1/3) * (normalize(followers_count) + normalize(favourites_count) + normalize(statuses_count))\n",
    "dfRaw = np.c_[dfRaw, score]\n",
    "worthKeeping += [\"popularity_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fee7ff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>verified_account</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>location</th>\n",
       "      <th>user_id</th>\n",
       "      <th>withheld_anywhere</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>popularity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHINE - Depuis le 1er janvier 2021, une loi pe...</td>\n",
       "      <td>{'id': 1184106601122156544, 'id_str': '1184106...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>529</td>\n",
       "      <td>None</td>\n",
       "      <td>1184106601122156544</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Balakot \\nPak Army is our pride â¤ï¸ğŸ‘</td>\n",
       "      <td>{'id': 966615015716458497, 'id_str': '96661501...</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>[Balakot]</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>93</td>\n",
       "      <td>None</td>\n",
       "      <td>966615015716458497</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº Ù„ÛŒÙ†Ø§ Ú†Ø§Û Ø±ÛÛŒÛ” \\nÛÙ…...</td>\n",
       "      <td>{'id': 407984569, 'id_str': '407984569', 'name...</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>753</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>407984569</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº Ù„ÛŒÙ†Ø§ Ú†Ø§Û Ø±ÛÛŒÛ” \\nÛÙ…...</td>\n",
       "      <td>{'id': 407984569, 'id_str': '407984569', 'name...</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>753</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>407984569</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø³ÛŒØ¯ Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ú©Ø§ ØªØ¹Ù„Ù‚ Ù‚Ø¨Ø§Ø¦Ù„ÛŒ Ø¶Ù„Ø¹ Ú©Ø±Ù… Ø³Û’ ÛÛ’Û” Ø§Ø­Ø³...</td>\n",
       "      <td>{'id': 1022545022447759360, 'id_str': '1022545...</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3526</td>\n",
       "      <td>None</td>\n",
       "      <td>1022545022447759360</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70883</th>\n",
       "      <td>à¸–à¹‰à¸²à¹„à¸”à¹‰à¸£à¸±à¸à¹ƒà¸„à¸£à¸ªà¸±à¸à¸„à¸™à¸‚à¸¶à¹‰à¸™à¸¡à¸²à¸ˆà¸£à¸´à¸‡à¹† à¸‰à¸±à¸™à¸„à¸‡à¹‚à¸­à¸šà¸à¸­à¸”à¸—à¸¸à¸à¸‚à¹‰...</td>\n",
       "      <td>{'id': 733700890129883136, 'id_str': '73370089...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>th</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>None</td>\n",
       "      <td>733700890129883136</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70884</th>\n",
       "      <td>ãƒªãƒ³ã‚¯ã®å¦–ç²¾ã€€ãƒ´ã‚£ã‚¯ãƒˆãƒ«ãƒ»ãƒ‹ã‚­ãƒ•ã‚©ãƒ­ãƒ•ï¼†\\nãŠèŠ±ç•‘ã®ã‚·ãƒ³ãƒ‡ãƒ¬ãƒ©ã€€ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ã‚¸ãƒ£ã‚³ãƒ¡ãƒƒãƒ†ã‚£...</td>\n",
       "      <td>{'id': 827750070724354048, 'id_str': '82775007...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ã‚¸ãƒ£ã‚³ãƒ¡ãƒƒãƒ†ã‚£ç”Ÿèª•ç¥­2021, ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ã‚¸ãƒ£ã‚³ãƒ¡ãƒƒãƒ†ã‚£èª•ç”Ÿç¥­2021, ã‚¯...</td>\n",
       "      <td>ja</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>None</td>\n",
       "      <td>827750070724354048</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70885</th>\n",
       "      <td></td>\n",
       "      <td>{'id': 1352109785383116805, 'id_str': '1352109...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>und</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>None</td>\n",
       "      <td>1352109785383116805</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70886</th>\n",
       "      <td>AÄLIYORUM Ã–ÄLE ARAMIZI 40 DAKÅKA YAPMIÅLAR AÄL...</td>\n",
       "      <td>{'id': 1322266379203022848, 'id_str': '1322266...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>tr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "      <td>None</td>\n",
       "      <td>1322266379203022848</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70887</th>\n",
       "      <td>The order.                         The creation</td>\n",
       "      <td>{'id': 4503699563, 'id_str': '4503699563', 'na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>340</td>\n",
       "      <td>None</td>\n",
       "      <td>4503699563</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70888 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      CHINE - Depuis le 1er janvier 2021, une loi pe...   \n",
       "1                  #Balakot \\nPak Army is our pride â¤ï¸ğŸ‘    \n",
       "2       Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº Ù„ÛŒÙ†Ø§ Ú†Ø§Û Ø±ÛÛŒÛ” \\nÛÙ…...   \n",
       "3       Ù„ÙˆÚ¯ÙˆÚº Ú©ÛŒ Ø§Ú©Ø«Ø±ÛŒØª ÛØ¯Ø§ÛŒØª Ù†ÛÛŒÚº Ù„ÛŒÙ†Ø§ Ú†Ø§Û Ø±ÛÛŒÛ” \\nÛÙ…...   \n",
       "4       Ø³ÛŒØ¯ Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ú©Ø§ ØªØ¹Ù„Ù‚ Ù‚Ø¨Ø§Ø¦Ù„ÛŒ Ø¶Ù„Ø¹ Ú©Ø±Ù… Ø³Û’ ÛÛ’Û” Ø§Ø­Ø³...   \n",
       "...                                                  ...   \n",
       "70883   à¸–à¹‰à¸²à¹„à¸”à¹‰à¸£à¸±à¸à¹ƒà¸„à¸£à¸ªà¸±à¸à¸„à¸™à¸‚à¸¶à¹‰à¸™à¸¡à¸²à¸ˆà¸£à¸´à¸‡à¹† à¸‰à¸±à¸™à¸„à¸‡à¹‚à¸­à¸šà¸à¸­à¸”à¸—à¸¸à¸à¸‚à¹‰...   \n",
       "70884   ãƒªãƒ³ã‚¯ã®å¦–ç²¾ã€€ãƒ´ã‚£ã‚¯ãƒˆãƒ«ãƒ»ãƒ‹ã‚­ãƒ•ã‚©ãƒ­ãƒ•ï¼†\\nãŠèŠ±ç•‘ã®ã‚·ãƒ³ãƒ‡ãƒ¬ãƒ©ã€€ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ã‚¸ãƒ£ã‚³ãƒ¡ãƒƒãƒ†ã‚£...   \n",
       "70885                                                      \n",
       "70886  AÄLIYORUM Ã–ÄLE ARAMIZI 40 DAKÅKA YAPMIÅLAR AÄL...   \n",
       "70887   The order.                         The creation    \n",
       "\n",
       "                                                    user  \\\n",
       "0      {'id': 1184106601122156544, 'id_str': '1184106...   \n",
       "1      {'id': 966615015716458497, 'id_str': '96661501...   \n",
       "2      {'id': 407984569, 'id_str': '407984569', 'name...   \n",
       "3      {'id': 407984569, 'id_str': '407984569', 'name...   \n",
       "4      {'id': 1022545022447759360, 'id_str': '1022545...   \n",
       "...                                                  ...   \n",
       "70883  {'id': 733700890129883136, 'id_str': '73370089...   \n",
       "70884  {'id': 827750070724354048, 'id_str': '82775007...   \n",
       "70885  {'id': 1352109785383116805, 'id_str': '1352109...   \n",
       "70886  {'id': 1322266379203022848, 'id_str': '1322266...   \n",
       "70887  {'id': 4503699563, 'id_str': '4503699563', 'na...   \n",
       "\n",
       "      withheld_in_countries  \\\n",
       "0                        []   \n",
       "1                      [IN]   \n",
       "2                      [IN]   \n",
       "3                      [IN]   \n",
       "4                      [IN]   \n",
       "...                     ...   \n",
       "70883                    []   \n",
       "70884                    []   \n",
       "70885                    []   \n",
       "70886                    []   \n",
       "70887                    []   \n",
       "\n",
       "                                                hashtags lang  \\\n",
       "0                                                     []   fr   \n",
       "1                                              [Balakot]   en   \n",
       "2                                                     []   ur   \n",
       "3                                                     []   ur   \n",
       "4                                                     []   ur   \n",
       "...                                                  ...  ...   \n",
       "70883                                                 []   th   \n",
       "70884  [ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ã‚¸ãƒ£ã‚³ãƒ¡ãƒƒãƒ†ã‚£ç”Ÿèª•ç¥­2021, ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ã‚¸ãƒ£ã‚³ãƒ¡ãƒƒãƒ†ã‚£èª•ç”Ÿç¥­2021, ã‚¯...   ja   \n",
       "70885                                                 []  und   \n",
       "70886                                                 []   tr   \n",
       "70887                                                 []   en   \n",
       "\n",
       "      possibly_sensitive verified_account followers_count  location  \\\n",
       "0                    0.0            False             529      None   \n",
       "1                    0.0            False              93      None   \n",
       "2                    0.0            False             753  Pakistan   \n",
       "3                    0.0            False             753  Pakistan   \n",
       "4                    0.0            False            3526      None   \n",
       "...                  ...              ...             ...       ...   \n",
       "70883                0.0            False             110      None   \n",
       "70884                0.0            False              29      None   \n",
       "70885                0.0            False              28      None   \n",
       "70886                0.0            False              81      None   \n",
       "70887                1.0            False             340      None   \n",
       "\n",
       "                   user_id withheld_anywhere  neg    neu    pos compound  \\\n",
       "0      1184106601122156544             False  0.0    0.0    0.0      0.0   \n",
       "1       966615015716458497              True  0.0  0.789  0.211     0.34   \n",
       "2                407984569              True  0.0    0.0    0.0      0.0   \n",
       "3                407984569              True  0.0    0.0    0.0      0.0   \n",
       "4      1022545022447759360              True  0.0    0.0    0.0      0.0   \n",
       "...                    ...               ...  ...    ...    ...      ...   \n",
       "70883   733700890129883136             False  0.0    0.0    0.0      0.0   \n",
       "70884   827750070724354048             False  0.0    0.0    0.0      0.0   \n",
       "70885  1352109785383116805             False  0.0    0.0    0.0      0.0   \n",
       "70886  1322266379203022848             False  0.0    0.0    0.0      0.0   \n",
       "70887           4503699563             False  0.0  0.588  0.412   0.2732   \n",
       "\n",
       "      popularity_score  \n",
       "0             0.000075  \n",
       "1             0.000542  \n",
       "2             0.007183  \n",
       "3             0.007183  \n",
       "4             0.020478  \n",
       "...                ...  \n",
       "70883         0.002502  \n",
       "70884         0.012251  \n",
       "70885         0.000358  \n",
       "70886         0.000347  \n",
       "70887         0.002595  \n",
       "\n",
       "[70888 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reassemble the data in a pandas dataframe\n",
    "df_cen = pd.DataFrame(dfRaw, columns = worthKeeping)\n",
    "df_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb64a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanCols = filter(lambda x: x != \"user\", worthKeeping)\n",
    "df_clean = df_cen[cleanCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb895a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.NUMBER, p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED, \\\n",
    "              p.OPT.HASHTAG, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "df_processed = df_clean.copy()\n",
    "df_processed[\"text\"] = df_clean.apply({\"text\": lambda line: p.clean(line)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0100a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noduplicates = df_processed.copy()\n",
    "df_noduplicates['withheld_in_countries'] = df_processed['withheld_in_countries'].astype(str)\n",
    "df_noduplicates['hashtags'] = df_processed['hashtags'].astype(str)\n",
    "\n",
    "df_noduplicates.drop_duplicates()\n",
    "cleanCols = filter(lambda x: x != \"user\", worthKeeping)\n",
    "df_clean = df_noduplicates[cleanCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9f51346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_english = df_noduplicates[df_noduplicates['lang'] == \"en\"] \n",
    "#df_turkish = df_noduplicates[df_noduplicates['lang'] == \"tr\"] \n",
    "#df_urdu = df_noduplicates[df_noduplicates['lang'] == \"ur\"]\n",
    "#df_japanese = df_noduplicates[df_noduplicates['lang'] == \"ja\"] \n",
    "#df_spanish = df_noduplicates[df_noduplicates['lang'] == \"es\"] \n",
    "#df_thai = df_noduplicates[df_noduplicates['lang'] == \"th\"] \n",
    "#df_portuguese = df_noduplicates[df_noduplicates['lang'] == \"pt\"] \n",
    "#df_arabic = df_noduplicates[df_noduplicates['lang'] == \"ar\"] \n",
    "#df_indian = df_noduplicates[df_noduplicates['lang'] == \"in\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53c247a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25830, 15)\n"
     ]
    }
   ],
   "source": [
    "df_english = df_clean[df_noduplicates['lang'] == \"en\"] \n",
    "print(df_english.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5546795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_CSV = False\n",
    "if TO_CSV:\n",
    "    df_english.to_csv('df_english_clean', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628207d",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b400a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer(stop_words='english')\n",
    "#vectorizer.fit(flat_list_text_tokenized)\n",
    "#def bow_tranform_wrapper(sentences): \n",
    "#    if isinstance(sentences, list): \n",
    "#        return vectorizer.transform(sentences)\n",
    "#    else:\n",
    "#        print('Not a list! Ingore message: ' + str(sentences))\n",
    "#        return vectorizer.transform([sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f13b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_m/v82wb7j964v3b7b70x4rrvvr0000gn/T/ipykernel_60898/2991236561.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english[\"withheld_anywhere\"] = df_english[\"withheld_anywhere\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_english[\"withheld_anywhere\"] = df_english[\"withheld_anywhere\"].astype(int)\n",
    "y = df_english[\"withheld_anywhere\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37d58777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25830\n",
      "Pak Army is our pride\n"
     ]
    }
   ],
   "source": [
    "all_tweets = [sentence for sentence in list(df_english['text'].values)]\n",
    "print(len(all_tweets))\n",
    "print(all_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3706dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(all_tweets) \n",
    "tfdif_text = tfidf_model.transform(list(df_english['text'].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4a6e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25830, 24402)\n"
     ]
    }
   ],
   "source": [
    "print(tfdif_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87c62ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_model = CountVectorizer()\n",
    "bow_model.fit(all_tweets)\n",
    "bow_texts = bow_model.transform(list(df_english['text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feae6390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25830, 24402)\n"
     ]
    }
   ],
   "source": [
    "print(bow_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac339754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pak Army is our pride\n"
     ]
    }
   ],
   "source": [
    "print(all_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b79cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c1f2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57213351e14b43c2abe951ebf4ff741c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/808 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "embeddings = model.encode(sentences=all_tweets, batch_size=32, show_progress_bar=True, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9061ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets_embeddings.pickle', 'wb') as pkl:\n",
    "    pickle.dump(embeddings, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10095484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english['text_embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_label = preprocessing.LabelEncoder()\n",
    "countries_encoded = country_label.fit_transform(list(df_english.location.values))\n",
    "df_english['Country_encoded'] = countries_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644940fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english['Country_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb91764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df_english.astype({\"possibly_sensitive\": float, \"verified_account\": float,\\\n",
    "                                'followers_count':int, 'user_id': int, 'neg': float, 'neu': float, \n",
    "                               'pos': float, 'compound': float, 'popularity_score': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_english['text_tokenized_list'] = text_tokenized_list\n",
    "#sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "#sentence_embeddings = sbert_model.encode(text_tokenized_list)\n",
    "#df_english['text_embeddings'] = sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded = ['possibly_sensitive', 'verified_account',\\\n",
    "                    'followers_count', 'user_id', 'neg', 'neu', \\\n",
    "                    'pos', 'compound', 'popularity_score', 'text_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_english[features_encoded].copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70894088",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dac2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad62f421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20664, 9)\n",
      "(5166, 9)\n",
      "(20664,)\n",
      "(5166,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e718175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      2053\n",
      "        True       0.60      1.00      0.75      3113\n",
      "\n",
      "    accuracy                           0.60      5166\n",
      "   macro avg       0.30      0.50      0.38      5166\n",
      "weighted avg       0.36      0.60      0.45      5166\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.62      0.71      2053\n",
      "        True       0.78      0.91      0.84      3113\n",
      "\n",
      "    accuracy                           0.80      5166\n",
      "   macro avg       0.80      0.77      0.77      5166\n",
      "weighted avg       0.80      0.80      0.79      5166\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      2053\n",
      "        True       0.60      1.00      0.75      3113\n",
      "\n",
      "    accuracy                           0.60      5166\n",
      "   macro avg       0.30      0.50      0.38      5166\n",
      "weighted avg       0.36      0.60      0.45      5166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vincentdandenault/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "models = {'SVM': SVC(random_state=seed), \n",
    "          'Random Forest': RandomForestClassifier(random_state=seed), \n",
    "          'Gaussian Naive Bayes': GaussianNB()}\n",
    "scores = {}\n",
    "for name in models.keys(): \n",
    "    y_pred = models[name].fit(X_train, y_train).predict(X_test)\n",
    "    target_names = ['False', 'True']\n",
    "    res = classification_report(y_test, y_pred, target_names=target_names) \n",
    "    print(name)\n",
    "    print(res)\n",
    "    scores[name] = res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1159a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"SVM\": \"              precision    recall  f1-score   support\\n\\n       False       0.00      0.00      0.00      2053\\n        True       0.60      1.00      0.75      3113\\n\\n    accuracy                           0.60      5166\\n   macro avg       0.30      0.50      0.38      5166\\nweighted avg       0.36      0.60      0.45      5166\\n\", \"Random Forest\": \"              precision    recall  f1-score   support\\n\\n       False       0.82      0.62      0.71      2053\\n        True       0.78      0.91      0.84      3113\\n\\n    accuracy                           0.80      5166\\n   macro avg       0.80      0.77      0.77      5166\\nweighted avg       0.80      0.80      0.79      5166\\n\", \"Gaussian Naive Bayes\": \"              precision    recall  f1-score   support\\n\\n       False       0.00      0.00      0.00      2053\\n        True       0.60      1.00      0.75      3113\\n\\n    accuracy                           0.60      5166\\n   macro avg       0.30      0.50      0.38      5166\\nweighted avg       0.36      0.60      0.45      5166\\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f55e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
