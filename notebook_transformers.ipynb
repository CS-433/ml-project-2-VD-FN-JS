{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d__2kjNBHskh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downloads"
      ],
      "metadata": {
        "id": "3Qr0M2SzHS4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install preprocessor\n",
        "!pip install vaderSentiment\n",
        "!pip install torchmetrics\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5S8X4PutBIf",
        "outputId": "00a3c118-ec0d-4ff4-f960-61d1d86aaf14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: preprocessor in /usr/local/lib/python3.8/dist-packages (1.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.8/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (5.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly) (8.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "bO98axTwHWr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tvPM-LXFsp30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f84dde-ce2f-4cdb-83ff-039be8092db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import preprocessor as p\n",
        "import re\n",
        "import numpy as np\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
        "from transformers import RobertaConfig, RobertaModel, RobertaForSequenceClassification, RobertaTokenizer\n",
        "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
        "from transformers import ElectraConfig, ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
        "\n",
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "w6awx83KJNZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = 'df_english_clean'\n",
        "seed_val = 42\n",
        "MODEL = 'ELECTRA' #'BERT', 'ELECTRA'"
      ],
      "metadata": {
        "id": "RzUwBqzJJPBt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Import \n",
        "See README for Instructions"
      ],
      "metadata": {
        "id": "d__2kjNBHskh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(dir_path)"
      ],
      "metadata": {
        "id": "yiqUkFGUs-6m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qFKwnDWGtM-y",
        "outputId": "cb0867b5-4b97-4bbd-9234-5a45ea59387c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text withheld_in_countries  \\\n",
              "0                              Pak Army is our pride                ['IN']   \n",
              "1  Ben Dunk \"If you haven't seen Lahore, you have...                ['IN']   \n",
              "2  India has also bestowed Abhinandan Varthaman w...                ['IN']   \n",
              "3  After the great Companion Saad bin Muadh embra...                ['RU']   \n",
              "4  After the great Companion Saad bin Muadh embra...                ['RU']   \n",
              "5  Paying homage to one of the great pilots in th...                ['IN']   \n",
              "6  Paying homage to one of the great pilots in th...                ['IN']   \n",
              "7                              STRIP CHAT STRIP CHAT                ['DE']   \n",
              "8  Champions of Democracy are in fact champions o...                ['IN']   \n",
              "9  Militant commander Nooristan known as Hasan Ba...                ['IN']   \n",
              "\n",
              "                      hashtags lang  possibly_sensitive  verified_account  \\\n",
              "0                  ['Balakot']   en                 0.0             False   \n",
              "1                           []   en                 0.0             False   \n",
              "2  ['ہماراایمان_دفاع_پاکستان']   en                 0.0             False   \n",
              "3                           []   en                 0.0             False   \n",
              "4                           []   en                 0.0             False   \n",
              "5               ['Abhinandan']   en                 0.0             False   \n",
              "6               ['Abhinandan']   en                 0.0             False   \n",
              "7                           []   en                 1.0             False   \n",
              "8                           []   en                 0.0             False   \n",
              "9          ['SouthWaziristan']   en                 0.0             False   \n",
              "\n",
              "   followers_count              location              user_id  \\\n",
              "0               93                   NaN   966615015716458497   \n",
              "1             3525                   NaN  1022545022447759360   \n",
              "2             3746  United Arab Emirates  1178014718029651969   \n",
              "3              354                   NaN  1043725274280538112   \n",
              "4              354                   NaN  1043725274280538112   \n",
              "5              411              Pakistan  1182959113929740296   \n",
              "6              411              Pakistan  1182959113929740296   \n",
              "7           195344                   NaN            148782077   \n",
              "8             1961              Pakistan  1322144832987537409   \n",
              "9             1036              Pakistan  1270480467310055426   \n",
              "\n",
              "   withheld_anywhere    neg    neu    pos  compound  popularity_score  \n",
              "0                  1  0.000  0.789  0.211    0.3400          0.000542  \n",
              "1                  1  0.000  1.000  0.000    0.0000          0.020472  \n",
              "2                  1  0.000  0.788  0.212    0.5423          0.013798  \n",
              "3                  1  0.097  0.761  0.142    0.3182          0.001412  \n",
              "4                  1  0.097  0.761  0.142    0.3182          0.001412  \n",
              "5                  1  0.052  0.545  0.403    0.9313          0.000790  \n",
              "6                  1  0.052  0.545  0.403    0.9313          0.000790  \n",
              "7                  1  0.000  1.000  0.000    0.0000          0.022920  \n",
              "8                  1  0.107  0.657  0.235    0.5719          0.001448  \n",
              "9                  1  0.000  0.881  0.119    0.3182          0.003920  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf470dbc-587c-428f-8b65-2b1f247c4b9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>withheld_in_countries</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>lang</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>verified_account</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>location</th>\n",
              "      <th>user_id</th>\n",
              "      <th>withheld_anywhere</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "      <th>popularity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pak Army is our pride</td>\n",
              "      <td>['IN']</td>\n",
              "      <td>['Balakot']</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>93</td>\n",
              "      <td>NaN</td>\n",
              "      <td>966615015716458497</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.789</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0.3400</td>\n",
              "      <td>0.000542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ben Dunk \"If you haven't seen Lahore, you have...</td>\n",
              "      <td>['IN']</td>\n",
              "      <td>[]</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>3525</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1022545022447759360</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.020472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>India has also bestowed Abhinandan Varthaman w...</td>\n",
              "      <td>['IN']</td>\n",
              "      <td>['ہماراایمان_دفاع_پاکستان']</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>3746</td>\n",
              "      <td>United Arab Emirates</td>\n",
              "      <td>1178014718029651969</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.788</td>\n",
              "      <td>0.212</td>\n",
              "      <td>0.5423</td>\n",
              "      <td>0.013798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After the great Companion Saad bin Muadh embra...</td>\n",
              "      <td>['RU']</td>\n",
              "      <td>[]</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>354</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1043725274280538112</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.761</td>\n",
              "      <td>0.142</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>0.001412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After the great Companion Saad bin Muadh embra...</td>\n",
              "      <td>['RU']</td>\n",
              "      <td>[]</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>354</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1043725274280538112</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.761</td>\n",
              "      <td>0.142</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>0.001412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Paying homage to one of the great pilots in th...</td>\n",
              "      <td>['IN']</td>\n",
              "      <td>['Abhinandan']</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>411</td>\n",
              "      <td>Pakistan</td>\n",
              "      <td>1182959113929740296</td>\n",
              "      <td>1</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.545</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.9313</td>\n",
              "      <td>0.000790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Paying homage to one of the great pilots in th...</td>\n",
              "      <td>['IN']</td>\n",
              "      <td>['Abhinandan']</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>411</td>\n",
              "      <td>Pakistan</td>\n",
              "      <td>1182959113929740296</td>\n",
              "      <td>1</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.545</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.9313</td>\n",
              "      <td>0.000790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>STRIP CHAT STRIP CHAT</td>\n",
              "      <td>['DE']</td>\n",
              "      <td>[]</td>\n",
              "      <td>en</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>195344</td>\n",
              "      <td>NaN</td>\n",
              "      <td>148782077</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.022920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Champions of Democracy are in fact champions o...</td>\n",
              "      <td>['IN']</td>\n",
              "      <td>[]</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1961</td>\n",
              "      <td>Pakistan</td>\n",
              "      <td>1322144832987537409</td>\n",
              "      <td>1</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.657</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>0.001448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Militant commander Nooristan known as Hasan Ba...</td>\n",
              "      <td>['IN']</td>\n",
              "      <td>['SouthWaziristan']</td>\n",
              "      <td>en</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1036</td>\n",
              "      <td>Pakistan</td>\n",
              "      <td>1270480467310055426</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.119</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>0.003920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf470dbc-587c-428f-8b65-2b1f247c4b9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf470dbc-587c-428f-8b65-2b1f247c4b9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf470dbc-587c-428f-8b65-2b1f247c4b9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing and Feature Encoding"
      ],
      "metadata": {
        "id": "aE8Lri5StfgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"withheld_anywhere\"] = df[\"withheld_anywhere\"].astype(int)\n",
        "labels = np.array(df[\"withheld_anywhere\"])"
      ],
      "metadata": {
        "id": "uzeY9_WRtdi8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def word_tokenize_wrapper(sentence): \n",
        "    if isinstance(sentence, str): \n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        tokens_without_sw = [word for word in words if not word in stopwords.words('english')]\n",
        "        limitized_words = [lemmatizer.lemmatize(word) for word in tokens_without_sw]\n",
        "        return tokens_without_sw\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "text_tokenized_list = list(df.apply(lambda x: word_tokenize_wrapper(x['text']), axis=1))\n",
        "cleaned_sentences = []\n",
        "for sentences in text_tokenized_list:\n",
        "    sentence = \" \".join(sentences)\n",
        "    cleaned_sentences.append(sentence)"
      ],
      "metadata": {
        "id": "fr0W6mQ1thel"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "3ttA6VSiuLam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "if MODEL == 'ROBERTA':\n",
        "  tokenizer =  BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "  model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels = 2,  \n",
        "    output_attentions = False,\n",
        "    return_dict=False,\n",
        "    output_hidden_states = False)\n",
        "  \n",
        "elif MODEL == 'ELECTRA': \n",
        "  configuration = ElectraConfig()\n",
        "  model = ElectraModel(configuration)\n",
        "  configuration = model.config\n",
        "  tokenizer = ElectraTokenizer.from_pretrained(\"bhadresh-savani/electra-base-emotion\")\n",
        "  model = ElectraForSequenceClassification.from_pretrained(\"bhadresh-savani/electra-base-emotion\", \n",
        "    num_labels = 2,  \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False, \n",
        "    return_dict=False,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "else: \n",
        "  tokenizer =  BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "  model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2,  \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False, \n",
        "    return_dict=False\n",
        ")\n",
        "  \n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qpvr-onKDI8",
        "outputId": "88b0a367-4065-4844-d4d3-29e963090ec4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/electra-base-emotion and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([6, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "max_length = 0\n",
        "for tweet in cleaned_sentences:\n",
        "    max_length = max(max_length, len(tweet))\n",
        "\n",
        "for sentence in cleaned_sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,                  \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = max_length,       \n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt')\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print(input_ids.shape)\n",
        "print(attention_masks.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTVXHOv2ukw3",
        "outputId": "cba371f8-1ad5-494c-c781-a781d4fe4ea3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25830, 156])\n",
            "torch.Size([25830, 156])\n",
            "torch.Size([25830])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Hyperparameters\n",
        "batch_size = 32\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
        "epochs = 6\n",
        "division = 0.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc4gpfAnJFbi",
        "outputId": "d0c8932f-e259-4bb5-fb94-a080f90dfdb4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "dataset_length = len(dataset)\n",
        "train_size = int(division * dataset_length)\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, (dataset_length - train_size)])\n",
        "train_dataloader = DataLoader(train_dataset,  sampler = RandomSampler(train_dataset), batch_size = batch_size)\n",
        "validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "6NjUH0PJxx3E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "y_true = []\n",
        "def keep_flat_labels(preds, labels): \n",
        "  y_pred.extend(np.argmax(preds, axis=1).flatten())\n",
        "  y_true.extend(labels.flatten())\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "VoWICbXmz4Lb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "training_stats = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    tot_train_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()        \n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        tot_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = tot_train_loss / len(train_dataloader)            \n",
        "    print(\"\\n Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "        total_eval_loss += loss.item()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        keep_flat_labels(logits, label_ids)\n",
        "        \n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWte01IAwsDR",
        "outputId": "7a1a1078-c9b3-4980-96ca-9611b979f6b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 6 ========\n",
            "\n",
            " Average training loss: 0.52\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.44\n",
            "======== Epoch 2 / 6 ========\n",
            "\n",
            " Average training loss: 0.41\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.38\n",
            "======== Epoch 3 / 6 ========\n",
            "\n",
            " Average training loss: 0.34\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.37\n",
            "======== Epoch 4 / 6 ========\n",
            "\n",
            " Average training loss: 0.29\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.38\n",
            "======== Epoch 5 / 6 ========\n",
            "\n",
            " Average training loss: 0.27\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.37\n",
            "======== Epoch 6 / 6 ========\n",
            "\n",
            " Average training loss: 0.25\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats).set_index('epoch')\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "YFaUofry0Lly",
        "outputId": "a192ed71-7c28-4418-c8ab-f1bc577662d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur.\n",
              "epoch                                           \n",
              "1               0.52         0.44           0.80\n",
              "2               0.41         0.38           0.84\n",
              "3               0.34         0.37           0.85\n",
              "4               0.29         0.38           0.85\n",
              "5               0.27         0.37           0.86\n",
              "6               0.25         0.37           0.86"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ff6f036-8ccb-4d31-b616-deef588bc273\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ff6f036-8ccb-4d31-b616-deef588bc273')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ff6f036-8ccb-4d31-b616-deef588bc273 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ff6f036-8ccb-4d31-b616-deef588bc273');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Visualization"
      ],
      "metadata": {
        "id": "SBNlBLsCJhPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = classification_report(y_true, y_pred, target_names=['Not Censord', 'Censord']) \n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2kOvSkM0I77",
        "outputId": "3c1de55d-6c90-42e7-ce9a-4f8b2ec5b065"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not Censord       0.78      0.83      0.80     12048\n",
            "     Censord       0.89      0.85      0.87     18948\n",
            "\n",
            "    accuracy                           0.84     30996\n",
            "   macro avg       0.83      0.84      0.83     30996\n",
            "weighted avg       0.84      0.84      0.84     30996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df_stats['Training Loss'], 'r-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'b-o', label=\"Validation\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.xlabel(\"Epoch Number\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks([1, 2, 3, 4, 5, 6])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dhPPdsZIy-JV",
        "outputId": "61bf020c-bea4-48fc-df60-9025d0fff010"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#source: https://plotly.com/python/roc-and-pr-curves/\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
        "fig = px.area(\n",
        "    x=fpr, y=tpr,\n",
        "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
        "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
        "    width=700, height=500\n",
        ")\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "\n",
        "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "fig.update_xaxes(constrain='domain')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "pC2ckntbO3M3",
        "outputId": "583039d5-aad7-4b05-ea10-5ac8c889fa34"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b425d80a-c5fe-4029-a6b0-37e6d94592a3\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b425d80a-c5fe-4029-a6b0-37e6d94592a3\")) {                    Plotly.newPlot(                        \"b425d80a-c5fe-4029-a6b0-37e6d94592a3\",                        [{\"hovertemplate\":\"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.16907370517928286,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.8478467384420519,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8394)\"},\"height\":500,\"width\":700,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b425d80a-c5fe-4029-a6b0-37e6d94592a3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}